{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=PV0uxIfy_-A&list=PLSctmZJ-z2wOY6q5jHdPpXmcsEhZZ3Oj_&index=62\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def find_corners(h):\n",
    "    h = h.reshape((4,2))\n",
    "    hnew = np.zeros((4,2),dtype = np.float32)\n",
    "\n",
    "    add = h.sum(1)\n",
    "    hnew[0] = h[np.argmin(add)]\n",
    "    hnew[2] = h[np.argmax(add)]\n",
    "\n",
    "    diff = np.diff(h,axis = 1)\n",
    "    hnew[1] = h[np.argmin(diff)]\n",
    "    hnew[3] = h[np.argmax(diff)]\n",
    "\n",
    "    return hnew\n",
    "\n",
    "#read in the image\n",
    "image=cv2.imread(\"sam1.jpg\")   \n",
    "#resizing because opencv does not work well with bigger images\n",
    "image=cv2.resize(image,(1300,800)) \n",
    "orig=image.copy()\n",
    "\n",
    "#RGB To Gray Scale\n",
    "gray=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)  \n",
    "cv2.imshow(\"Title\",gray)\n",
    "\n",
    "#(5,5) is the kernel size and 0 is sigma that determines the amount of blur\n",
    "blurred=cv2.GaussianBlur(gray,(5,5),0)  \n",
    "cv2.imshow(\"Blur\",blurred)\n",
    "\n",
    "#30 MinThreshold and 50 is the MaxThreshold\n",
    "edged=cv2.Canny(blurred,30,50)  \n",
    "cv2.imshow(\"Canny\",edged)\n",
    "\n",
    "\n",
    "contours,hierarchy=cv2.findContours(edged,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)  \n",
    "#retrieve the contours as a list, with simple apprximation model\n",
    "contours=sorted(contours,key=cv2.contourArea,reverse=True)\n",
    "\n",
    "#the loop extracts the boundary contours of the page\n",
    "for c in contours:\n",
    "    p=cv2.arcLength(c,True)\n",
    "    approx=cv2.approxPolyDP(c,0.02*p,True)\n",
    "\n",
    "    if len(approx)==4:\n",
    "        target=approx\n",
    "        break\n",
    "\n",
    "    \n",
    "#find endpoints of the sheet\n",
    "approx=find_corners(target) \n",
    "\n",
    "#map to 800*800 target window\n",
    "pts=np.float32([[0,0],[800,0],[800,800],[0,800]])  \n",
    "\n",
    "#get the top or bird eye view effect\n",
    "op=cv2.getPerspectiveTransform(approx,pts)  \n",
    "dst=cv2.warpPerspective(orig,op,(800,800))\n",
    "\n",
    "\n",
    "cv2.imshow(\"Scanned\",dst)\n",
    "# press q or Esc to close\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krawc\\OneDrive\\Documents\\code\\pythons\\text-circus\\test\\opencv.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mperspective\u001b[39;00m \u001b[39mimport\u001b[39;00m four_point_transform\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpytesseract\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m \u001b[39m+\u001b[39m cv2\u001b[39m.\u001b[39mCAP_DSHOW)\n",
      "File \u001b[1;32mc:\\Users\\krawc\\OneDrive\\Documents\\code\\pythons\\text-circus\\.venv\\Lib\\site-packages\\imutils\\perspective.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# author:    Adrian Rosebrock\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# website:   http://www.pyimagesearch.com\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[39m# import the necessary packages\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m \u001b[39mimport\u001b[39;00m distance \u001b[39mas\u001b[39;00m dist\n\u001b[0;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=W3DzSm8WI1g&list=PLSctmZJ-z2wOY6q5jHdPpXmcsEhZZ3Oj_&index=63\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.perspective import four_point_transform\n",
    "import pytesseract\n",
    "\n",
    "cap = cv2.VideoCapture(0 + cv2.CAP_DSHOW)\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "count = 0\n",
    "scale = 0.5\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "WIDTH, HEIGHT = 1920, 1080\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, HEIGHT)\n",
    "\n",
    "\n",
    "def image_processing(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    _, threshold = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return threshold\n",
    "\n",
    "\n",
    "def scan_detection(image):\n",
    "    global document_contour\n",
    "\n",
    "    document_contour = np.array([[0, 0], [WIDTH, 0], [WIDTH, HEIGHT], [0, HEIGHT]])\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, threshold = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    contours, _ = cv2.findContours(threshold, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    max_area = 0\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 1000:\n",
    "            peri = cv2.arcLength(contour, True)\n",
    "            approx = cv2.approxPolyDP(contour, 0.015 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                document_contour = approx\n",
    "                max_area = area\n",
    "\n",
    "    cv2.drawContours(frame, [document_contour], -1, (0, 255, 0), 3)\n",
    "\n",
    "\n",
    "def center_text(image, text):\n",
    "    text_size = cv2.getTextSize(text, font, 2, 5)[0]\n",
    "    text_x = (image.shape[1] - text_size[0]) // 2\n",
    "    text_y = (image.shape[0] + text_size[1]) // 2\n",
    "    cv2.putText(image, text, (text_x, text_y), font, 2, (255, 0, 255), 5, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "    frame_copy = frame.copy()\n",
    "\n",
    "    scan_detection(frame_copy)\n",
    "\n",
    "    cv2.imshow(\"input\", cv2.resize(frame, (int(scale * WIDTH), int(scale * HEIGHT))))\n",
    "\n",
    "    warped = four_point_transform(frame_copy, document_contour.reshape(4, 2))\n",
    "    cv2.imshow(\"Warped\", cv2.resize(warped, (int(scale * warped.shape[1]), int(scale * warped.shape[0]))))\n",
    "\n",
    "    processed = image_processing(warped)\n",
    "    processed = processed[10:processed.shape[0] - 10, 10:processed.shape[1] - 10]\n",
    "    cv2.imshow(\"Processed\", cv2.resize(processed, (int(scale * processed.shape[1]),\n",
    "                                                   int(scale * processed.shape[0]))))\n",
    "\n",
    "    pressed_key = cv2.waitKey(1) & 0xFF\n",
    "    if pressed_key == 27:\n",
    "        break\n",
    "\n",
    "    elif pressed_key == ord('s'):\n",
    "        cv2.imwrite(\"output/scanned_\" + str(count) + \".jpg\", processed)\n",
    "        count += 1\n",
    "\n",
    "        center_text(frame, \"Scan Saved\")\n",
    "        cv2.imshow(\"input\", cv2.resize(frame, (int(scale * WIDTH), int(scale * HEIGHT))))\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "    elif pressed_key == ord('o'):\n",
    "        file = open(\"output/recognized_\" + str(count - 1) + \".txt\", \"w\")\n",
    "        ocr_text = pytesseract.image_to_string(warped)\n",
    "        # print(ocr_text)\n",
    "        file.write(ocr_text)\n",
    "        file.close()\n",
    "\n",
    "        center_text(frame, \"Text Saved\")\n",
    "        cv2.imshow(\"input\", cv2.resize(frame, (int(scale * WIDTH), int(scale * HEIGHT))))\n",
    "        cv2.waitKey(500)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krawc\\OneDrive\\Documents\\code\\pythons\\text-circus\\test\\opencv.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# if webCamFeed:success, img = cap.read()\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m# else:img = cv2.imread(pathImage)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mimread(pathImage)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(img, (widthImg, heightImg)) \u001b[39m# RESIZE IMAGE\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/krawc/OneDrive/Documents/code/pythons/text-circus/test/opencv.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m# CREATE A BLANK IMAGE FOR TESTING DEBUGING IF REQUIRED\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# https://www.youtube.com/watch?v=ON_JubFRw8M&list=PLSctmZJ-z2wOY6q5jHdPpXmcsEhZZ3Oj_&index=64\n",
    "import cv2\n",
    "import numpy as np\n",
    "import utils as u\n",
    "\n",
    "\n",
    "########################################################################\n",
    "webCamFeed = True\n",
    "pathImage = \"sam1.jpg\"\n",
    "cap = cv2.VideoCapture(1)\n",
    "cap.set(10,160)\n",
    "widthImg  = 480#480\n",
    "heightImg = 400#640\n",
    "########################################################################\n",
    "\n",
    "u.initializeTrackbars()\n",
    "count=0\n",
    "\n",
    "while True:\n",
    "\n",
    "    # if webCamFeed:success, img = cap.read()\n",
    "    # else:img = cv2.imread(pathImage)\n",
    "    img = cv2.imread(pathImage)\n",
    "    img = cv2.resize(img, (widthImg, heightImg)) # RESIZE IMAGE\n",
    "\n",
    "    # CREATE A BLANK IMAGE FOR TESTING DEBUGING IF REQUIRED\n",
    "    imgBlank = np.zeros((heightImg,widthImg, 3), np.uint8) \n",
    "\n",
    "    # CONVERT IMAGE TO GRAY SCALE\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    # ADD GAUSSIAN BLUR\n",
    "    imgBlur = cv2.GaussianBlur(imgGray, (5, 5), 1) \n",
    "    # GET TRACK BAR VALUES FOR THRESHOLDS\n",
    "    thres=u.valTrackbars() \n",
    "    # APPLY CANNY BLUR\n",
    "    imgThreshold = cv2.Canny(imgBlur,thres[0],thres[1]) \n",
    "    kernel = np.ones((5, 5))\n",
    "    # APPLY DILATION\n",
    "    imgDial = cv2.dilate(imgThreshold, kernel, iterations=2) \n",
    "    # APPLY EROSION\n",
    "    imgThreshold = cv2.erode(imgDial, kernel, iterations=1)  \n",
    "\n",
    "    ## FIND ALL COUNTOURS\n",
    "    # COPY IMAGE FOR DISPLAY PURPOSES\n",
    "    imgContours = img.copy() \n",
    "    # COPY IMAGE FOR DISPLAY PURPOSES\n",
    "    imgBigContour = img.copy() \n",
    "    # FIND ALL CONTOURS\n",
    "    contours, hierarchy = cv2.findContours(imgThreshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    # DRAW ALL DETECTED CONTOURS\n",
    "    cv2.drawContours(imgContours, contours, -1, (0, 255, 0), 10) \n",
    "\n",
    "\n",
    "    # FIND THE BIGGEST COUNTOUR\n",
    "    # FIND THE BIGGEST CONTOUR\n",
    "    biggest, maxArea = u.biggestContour(contours) \n",
    "    if biggest.size != 0:\n",
    "        biggest=u.reorder(biggest)\n",
    "        # DRAW THE BIGGEST CONTOUR\n",
    "        cv2.drawContours(imgBigContour, biggest, -1, (0, 255, 0), 20) \n",
    "        imgBigContour = u.drawRectangle(imgBigContour,biggest,2)\n",
    "        pts1 = np.float32(biggest) # PREPARE POINTS FOR WARP\n",
    "        # PREPARE POINTS FOR WARP\n",
    "        pts2 = np.float32([[0, 0],[widthImg, 0], [0, heightImg],[widthImg, heightImg]]) \n",
    "        matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "        imgWarpColored = cv2.warpPerspective(img, matrix, (widthImg, heightImg))\n",
    "\n",
    "        #REMOVE 20 PIXELS FORM EACH SIDE\n",
    "        imgWarpColored=imgWarpColored[20:imgWarpColored.shape[0] - 20, 20:imgWarpColored.shape[1] - 20]\n",
    "        imgWarpColored = cv2.resize(imgWarpColored,(widthImg,heightImg))\n",
    "\n",
    "        # APPLY ADAPTIVE THRESHOLD\n",
    "        imgWarpGray = cv2.cvtColor(imgWarpColored,cv2.COLOR_BGR2GRAY)\n",
    "        imgAdaptiveThre= cv2.adaptiveThreshold(imgWarpGray, 255, 1, 1, 7, 2)\n",
    "        imgAdaptiveThre = cv2.bitwise_not(imgAdaptiveThre)\n",
    "        imgAdaptiveThre=cv2.medianBlur(imgAdaptiveThre,3)\n",
    "\n",
    "        # Image Array for Display\n",
    "        imageArray = ([img,imgGray,imgThreshold,imgContours],\n",
    "                      [imgBigContour,imgWarpColored, imgWarpGray,imgAdaptiveThre])\n",
    "\n",
    "    else:\n",
    "        imageArray = ([img,imgGray,imgThreshold,imgContours],\n",
    "                      [imgBlank, imgBlank, imgBlank, imgBlank])\n",
    "\n",
    "    # LABELS FOR DISPLAY\n",
    "    lables = [[\"Original\",\"Gray\",\"Threshold\",\"Contours\"],\n",
    "              [\"Biggest Contour\",\"Warp Prespective\",\"Warp Gray\",\"Adaptive Threshold\"]]\n",
    "\n",
    "    stackedImage = u.stackImages(imageArray,0.75,lables)\n",
    "    cv2.imshow(\"Result\",stackedImage)\n",
    "\n",
    "    # SAVE IMAGE WHEN 's' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        cv2.imwrite(\"Scanned/myImage\"+str(count)+\".jpg\",imgWarpColored)\n",
    "        cv2.rectangle(stackedImage, ((int(stackedImage.shape[1] / 2) - 230), int(stackedImage.shape[0] / 2) + 50),\n",
    "                      (1100, 350), (0, 255, 0), cv2.FILLED)\n",
    "        cv2.putText(stackedImage, \"Scan Saved\", (int(stackedImage.shape[1] / 2) - 200, int(stackedImage.shape[0] / 2)),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 3, (0, 0, 255), 5, cv2.LINE_AA)\n",
    "        cv2.imshow('Result', stackedImage)\n",
    "        cv2.waitKey(300)\n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
